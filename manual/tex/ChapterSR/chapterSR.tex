\chapter{The Substitution Ranking Module}
\label{rankers}

Substitution Ranking (SR) is the task of ranking a set of selected substitutions for a target complex word with respect to its simplicity. Approaches vary from simple word length and frequency-based measures \cite{Devlin1998,Carroll98,Carroll99,Biran2011} to more sophisticated linear combination as scoring functions \cite{uowshef} and Machine Learning approaches \cite{Horn2014}.

LEXenstein's SR module (lexenstein.rankers) provides access to $6$ approaches, each represented by a Python class. The following Sections describe each one individually.












\section{MetricRanker}

Employs a simple ranking strategy based on the values of a single feature provided by the user.

\subsection{Parameters}

During instantiation, the MetricRanker requires only a configured FeatureEstimator object, which must contain at least one feature that can be used as a metric for ranking. Once created, the user can retrieve rankings by using MetricRanker's ``getRankings'' function, which requires a VICTOR corpus and the index of a feature to be used as a ranking metric.

\subsection{Example}

The code snippet below shows the MetricRanker class being used:

\begin{lstlisting}
from lexenstein.features import *
from lexenstein.rankers import *

fe = FeatureEstimator()
fe.addCollocationalFeature('lm.bin', 0, 0, 'Complexity')
fe.addLengthFeature('Complexity')
fe.addSenseCountFeature('Simplicity')

mr = MetricRanker(fe)
frequency_ranks = mr.getRankings('lexmturk.txt', 0)
length_ranks = mr.getRankings('lexmturk.txt', 1)
sense_ranks = mr.getRankings('lexmturk.txt', 2)
\end{lstlisting}










\section{SVMRanker}

Use Support Vector Machines in a setup that minimizes a loss function with respect to a ranking model. In LS, this strategy is the one employed in the experiments of \cite{Horn2014}, yielding promising results.

\subsection{Parameters}

During instantiation, the SVMRanker requires for a FeatureEstimator object and a path to the root installation folder of SVM-Rank \cite{svmrank}. The user can then use the ``getFeaturesFile'', ``getTrainingModel'', ``getScoresFile'' and ``getRankings'' to train SVM ranking models and rank candidate substitutions. For more information on these functions' parameters, please refer to LEXenstein's documentation and the example in the following Section.

\subsection{Example}

The code snippet below shows the SVMRanker class being used:

\begin{lstlisting}
from lexenstein.features import *
from lexenstein.rankers import *

fe = FeatureEstimator()
fe.addCollocationalFeature('lm.bin', 0, 0, 'Complexity')
fe.addLengthFeature('Complexity')
fe.addSenseCountFeature('Simplicity')

svmr = SVMRanker(fe, '/svm-rank/')
svmr.getFeaturesFile('lexmturk.txt', 'features.txt')
svmr.getTrainingModel('features.txt', 0.1, 0.1, 0, 'model.txt')
svmr.getScoresFile('features.txt', 'model.txt', 'scores.txt')
rankings = svmr.getRankings('features.txt', 'scores.txt')
\end{lstlisting}



















\section{BoundaryRanker}

Employs a novel strategy, in which ranking is framed as a binary classification task. During training, this approach assigns the label $1$ to all candidates of rank $1\geq r \geq p$, where $p$ is a range set by the user, and $0$ to the remaining candidates. It then trains a stochastic descent linear classifier based on the features specified in the FeatureEstimator object. During testing, candidate substitutions are ranked based on how far from $0$ they are.

\subsection{Parameters}

During instantiation, the BoundaryRanker requires only for a FeatureEstimator object. The user can then use the ``trainRanker'' function to train a ranking model, and the ``getRankings'' to rank the candidates of a VICTOR corpus. For more information on the training parameters supported by the ``trainRanker'' function, please refer to LEXenstein's documentation.

\subsection{Example}

The code snippet below shows the BoundaryRanker class being used:

\begin{lstlisting}
from lexenstein.features import *
from lexenstein.rankers import *

fe = FeatureEstimator()
fe.addCollocationalFeature('lm.bin', 0, 0, 'Complexity')
fe.addLengthFeature('Complexity')
fe.addSenseCountFeature('Simplicity')

br = BoundaryRanker(fe)
br.trainRanker('lexmturk.txt', 1, 'modified_huber', 'l1', 0.1, 0.1, 0.001)
rankings = br.getRankings('lexmturk.txt')
\end{lstlisting}















\section{SVMBoundaryRanker}

Employs the same strategy used by the BoundaryRanker class, but instead of learning a linear ranking model through Stochastic Gradient Descent, it learns a linear or non-linear model by using Support Vector Machines.

\subsection{Parameters}

During instantiation, the SVMBoundaryRanker requires only for a FeatureEstimator object. The user can then use the ``trainRanker'' function to train a ranking model, and the ``getRankings'' to rank the candidates of a VICTOR corpus. For more information on the training parameters supported by the ``trainRanker'' function, please refer to LEXenstein's documentation.

\subsection{Example}

The code snippet below shows the SVMBoundaryRanker class being used:

\begin{lstlisting}
from lexenstein.features import *
from lexenstein.rankers import *

fe = FeatureEstimator()
fe.addCollocationalFeature('lm.bin', 0, 0, 'Complexity')
fe.addLengthFeature('Complexity')
fe.addSenseCountFeature('Simplicity')

sbr = SVMBoundaryRanker(fe)
sbr.trainRanker('lexmturk.txt', 1, 10, 'poly', 2, 0.1, 1)
rankings = sbr.getRankings('lexmturk.txt')
\end{lstlisting}











\section{BiranRanker}

Employs the strategy of \cite{Biran2011}, which models complexity as a function of a word's length and frequency in corpora of complex and simple content. 

\subsection{Parameters}

As input, it requires for a language model trained over complex data, and a language model trained over simple data. To learn more on how to obtain these resources, please refer to Chapter~\ref{chapterresources}.

\subsection{Example}

The code snippet below shows the BiranRanker class being used:

\begin{lstlisting}
from lexenstein.rankers import *

br = BiranRanker('lm_complex.bin', 'lm_simple.bin')
rankings = br.getRankings('lexmturk.txt')
\end{lstlisting}















\section{YamamotoRanker}

Employs the strategy of \cite{Yamamoto2013}, which ranks words according to a weighted function that considers their frequency in a corpus of simple content, co-occurrence frequency with a target complex word, sense distance, point-wise mutual information and trigram frequencies.

\subsection{Parameters}

As input, it requires for a language model trained over a corpus of simple data and a co-occurrence model. To learn more on how to obtain these resources, please refer to Chapter~\ref{chapterresources}.

\subsection{Example}

The code snippet below shows the YamamotoRanker class being used:

\begin{lstlisting}
from lexenstein.rankers import *

yr = YamamotoRanker('lm_simple.bin', 'cooc_model.txt')
rankings = yr.getRankings('lexmturk.txt')
\end{lstlisting}















\section{BottRanker}

Employs the strategy of \cite{Bott2012}, which ranks words according to a weighted function that considers their length and frequency in a corpus of simple content.

\subsection{Parameters}

As input, it requires for a language model trained over a corpus of simple data. To learn more on how to obtain this resource, please refer to Chapter~\ref{chapterresources}.

\subsection{Example}

The code snippet below shows the BottRanker class being used:

\begin{lstlisting}
from lexenstein.rankers import *

br = BottRanker('lm_simple.bin')
rankings = br.getRankings('lexmturk.txt')
\end{lstlisting}











\section{GlavasRanker}

Employs the strategy of \cite{glavas2015}, which ranks words according to their average ranking, as determined by a given set of features.

\subsection{Parameters}

As input, it requires for a configured FeatureEstimator object. The FeatureEstimator object required must contain each and every feature that the user wishes to rank candidates with.

\subsection{Example}

The code snippet below shows the GlavasRanker class being used:

\begin{lstlisting}
from lexenstein.features import *
from lexenstein.rankers import *

fe = FeatureEstimator()
fe.addCollocationalFeature('lm.bin', 0, 0, 'Complexity')
fe.addLengthFeature('Complexity')
fe.addSenseCountFeature('Simplicity')

gr = GlavasRanker(fe)
rankings = gr.getRankings('lexmturk.txt')
\end{lstlisting}