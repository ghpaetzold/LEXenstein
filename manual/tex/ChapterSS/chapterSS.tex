\chapter{The Substitution Selection Module}
\label{selectors}

Substitution Selection (SS) is the task of selecting which substitutions from a given list can replace a complex word in a given sentence without altering its meaning. Most work addresses this task referring to the context of the complex word by employing Word Sense Disambiguation (WSD) approaches \cite{Sedding04,Nunes2013}, or by discarding substitutions which do not share the same POS tag of the target complex word \cite{Yamamoto2013,Paetzold2013}.

LEXenstein's SS module (lexenstein.selectors) provides access to $8$ approaches, each represented by a Python class. All classes have a ``selectCandidates'' function, which receives as input a set of candidate substitutions and a corpus in the VICTOR format. The candidate substitutions can be either a dictionary produced by a Substitution Generation approach, or a list of candidates that have been already selected by another Substitution Selection approach. This feature allows for multiple selectors to be used in sequence. The following Sections describe each of the classes in the LEXenstein SS module individually.







\section{WordVectorSelector}

Employs a novel strategy, in which a word vector model is used to determine which substitutions have the closest meaning to that of the sentence being simplified. It retrieves a user-defined percentage of the substitutions, which are ranked with respect to the cosine distance between its word vector and the sum of some, or all of the sentences' words, depending on the settings defined by the user.


\subsection{Parameters}

To create a WordVectorSelector object, you must provide a binary word vector model created with word$2$vec. To learn more on how to obtain this resource, please refer to Chapter~\ref{chapterresources}.

\subsection{Example}

The code snippet below shows the WordVectorSelector class being used:

\begin{lstlisting}
from lexenstein.morphadorner import MorphAdornerToolkit
from lexenstein.generators import *
from lexenstein.selectors import *
from lexenstein.spelling import *

nc = NorvigCorrector('spelling_model.bin', format='bin')

m = MorphAdornerToolkit('./morph/')

wg = WordnetGenerator(m, nc, './pos_model.tagger', './stanford-postagger.jar', '/usr/bin/java')
subs = wg.getSubstitutions('lexmturk.txt')

wordvecselector = WordVectorSelector('embeddings_model.bin', './pos_model.tagger', './stanford-postagger.jar', '/usr/bin/java')
selected = wordvecselector.selectCandidates(subs, 'lexmturk.txt', proportion=0.75, stop_words_file='stop_words.txt', onlyInformative=True, keepTarget=True, onePerWord=True)
\end{lstlisting}









\section{BiranSelector}

Employs the strategy described in \cite{Biran2011}, in which a word co-occurrence model is used to determine which substitutions have meaning similar to that of a target complex word.


\subsection{Parameters}

To create a BiranSelector object, you must provide a word co-occurrence model. To learn more on how to obtain this resource, please refer to Chapter~\ref{chapterresources}.

\subsection{Example}

The code snippet below shows the BiranSelector class being used:

\begin{lstlisting}
from lexenstein.morphadorner import MorphAdornerToolkit
from lexenstein.generators import *
from lexenstein.selectors import *
from lexenstein.spelling import *

nc = NorvigCorrector('spelling_model.bin', format='bin')

m = MorphAdornerToolkit('./morph/')

wg = WordnetGenerator(m, nc, './pos_model.tagger', './stanford-postagger.jar', '/usr/bin/java')
subs = wg.getSubstitutions('lexmturk.txt')

biranselector = BiranSelector('cooc_model.txt')
selected = biranselector.selectCandidates(subs, 'lexmturk.txt', common_distance=0.01, candidate_distance=0.9)
\end{lstlisting}














\section{WSDSelector}

Allows for the user to use many distinct classic WSD approaches in SS. It requires for the PyWSD \cite{pywsd} module to be installed, which includes the approaches presented by \cite{lesk} and \cite{wupalmer}, as well as baselines such as random and first senses. The user can use any of the aforementioned approaches through the WSDSelector class by changing instantiation parameters.

\subsection{Parameters}

During instantiation, the WSDSelector class requires only for you to provide an id for the WSD method that you desire to use for Substitution Selection. For the options available, please refer to LEXenstein's documentation.

\subsection{Example}

The code snippet below shows the WSDSelector class being used:

\begin{lstlisting}
from lexenstein.morphadorner import MorphAdornerToolkit
from lexenstein.generators import *
from lexenstein.selectors import *
from lexenstein.spelling import *

nc = NorvigCorrector('spelling_model.bin', format='bin')

m = MorphAdornerToolkit('./morph/')

wg = WordnetGenerator(m, nc, './pos_model.tagger', './stanford-postagger.jar', '/usr/bin/java')
subs = wg.getSubstitutions('lexmturk.txt')

wsdselector = WSDSelector('lesk')
selected = wsdselector.selectCandidates(subs, 'lexmturk.txt')
\end{lstlisting}
















\section{AluisioSelector}

Employs an SS strategy similar to the one introduced by \cite{Aluisio09}. It selects only those candidates which can assume the same POS tag as the target word.

\subsection{Parameters}

During instantiation, the AluisioSelector class requires for a POS tag conditional probability model, a binary POS tagging model, the path to a compiled version of the Stanford Tagger. To learn more on how to obtain these resources, please refer to Chapter~\ref{chapterresources}.

\subsection{Example}

The code snippet below shows the AluisioSelector class being used:

\begin{lstlisting}
from lexenstein.morphadorner import MorphAdornerToolkit
from lexenstein.generators import *
from lexenstein.selectors import *
from lexenstein.spelling import *

nc = NorvigCorrector('spelling_model.bin', format='bin')

m = MorphAdornerToolkit('./morph/')

wg = WordnetGenerator(m, nc, './pos_model.tagger', './stanford-postagger.jar', '/usr/bin/java')
subs = wg.getSubstitutions('lexmturk.txt')

aluisioselector = AluisioSelector('cond_prob.bin', './pos_model.tagger', './stanford-postagger.jar', '/usr/bin/java')
selected = aluisioselector.selectCandidates(subs, 'lexmturk.txt')
\end{lstlisting}














\section{BelderSelector}

Selects only those candidates which appear in the same word clusters in which a given target word is present. This strategy is inspired by the work of \cite{Belder2010}, in which synonyms are automatically extracted from a latent variable language model.

\subsection{Parameters}

During instantiation, the BelderSelector class requires for a file with clusters of words. To learn more on how to obtain this resource, please refer to Chapter~\ref{chapterresources}.

\subsection{Example}

The code snippet below shows the BelderSelector class being used:

\begin{lstlisting}
from lexenstein.morphadorner import MorphAdornerToolkit
from lexenstein.generators import *
from lexenstein.selectors import *
from lexenstein.spelling import *

nc = NorvigCorrector('spelling_model.bin', format='bin')

m = MorphAdornerToolkit('./morph/')

wg = WordnetGenerator(m, nc, './pos_model.tagger', './stanford-postagger.jar', '/usr/bin/java')
subs = wg.getSubstitutions('lexmturk.txt')

belderselector = BelderSelector('clusters.txt')
selected = belderselector.selectCandidates(subs, 'lexmturk.txt')
\end{lstlisting}









\section{BoundarySelector}

Employs a novel strategy, in which a Boundary Ranker is trained over a given set of features and then used to rank candidate substitutions according to how likely they are of being able to replace a target word without compromising the sentence's grammaticality or coherence.

\subsection{Parameters}

During instantiation, the BoundarySelector class requires for a BoundaryRanker object, which must be configured according to which features and resources the user intends to use to rank substitution candidates. The user can then use the ``trainSelector'' function to train the selector given a set of parameters, or the ``trainSelectorWithCrossValidation'' function to train it with cross-validation. Finally, the user can then retrieve a proportion of the candidate substitutions by using the ``selectCandidates'' function. For more information about the parameters of each function, please refer to LEXenstein's documentation.

\subsection{Example}

The code snippet below shows the BoundarySelector class being used:

\begin{lstlisting}
from lexenstein.morphadorner import MorphAdornerToolkit
from lexenstein.generators import *
from lexenstein.selectors import *
from lexenstein.features import *
from lexenstein.spelling import *
from lexenstein.rankers import *

nc = NorvigCorrector('spelling_model.bin', format='bin')

fe = FeatureEstimator()
fe.addCollocationalFeature('lm.txt', 0, 0, 'Complexity')
fe.addSenseCountFeature('Simplicity')

m = MorphAdornerToolkit('./morph/')

wg = WordnetGenerator(m, nc, './pos_model.tagger', './stanford-postagger.jar', '/usr/bin/java')
subs = wg.getSubstitutions('lexmturk.txt')

br = BoundaryRanker(fe)
bs = BoundarySelector(br)
bs.trainSelectorWithCrossValidation('lexmturk.txt', 1, 5, 0.25)
selected = bs.selectCandidates(subs, 'lexmturk.txt', 'temp.txt', 0.25)
\end{lstlisting}










\section{SVMBoundarySelector}

Employs the same strategy used by the BoundaryRankerSelector, but instead of learning a linear model estimated over Stochastic Gradient Descent, it learns an either linear or non-linear model through Support Vector Machines. It retrieves a user-defined percentage of a set of substitutions.

\subsection{Parameters}

During instantiation, the SVMBoundarySelector class requires for a SVMBoundaryRanker object, which must be configured according to which features and resources the user intends to use to rank substitution candidates. The user can then use the ``trainSelector'' function to train the selector given a set of parameters, or the ``trainSelectorWithCrossValidation'' function to train it with cross-validation. Finally, the user can then retrieve a proportion of the candidate substitutions by using the ``selectCandidates'' function. For more information about the parameters of each function, please refer to LEXenstein's documentation.

\subsection{Example}

The code snippet below shows the SVMBoundarySelector class being used:

\begin{lstlisting}
from lexenstein.morphadorner import MorphAdornerToolkit
from lexenstein.generators import *
from lexenstein.selectors import *
from lexenstein.features import *
from lexenstein.spelling import *
from lexenstein.rankers import *

nc = NorvigCorrector('spelling_model.bin', format='bin')

m = MorphAdornerToolkit('./morph/')

wg = WordnetGenerator(m, nc, './pos_model.tagger', './stanford-postagger.jar', '/usr/bin/java')
subs = wg.getSubstitutions('lexmturk.txt')

fe = FeatureEstimator()
fe.addCollocationalFeature('lm.bin', 0, 0, 'Complexity')
fe.addSenseCountFeature('Simplicity')

br = SVMBoundaryRanker(fe)
sbs = SVMBoundarySelector(br)
sbs.trainSelectorWithCrossValidation('lexmturk.txt', 1, 5, 0.25)
selected = sbs.selectCandidates(subs, 'lexmturk.txt', 'temp.txt', 0.25)
\end{lstlisting}










\section{SVMRankSelector}

Employs a novel strategy, in which a SVM Ranker is trained over a given set of features and then used to rank candidate substitutions according to how likely they are of being able to replace a target word without compromising the sentence's grammaticality or coherence. It retrieves a user-defined percentage of a set of substitutions.

\subsection{Parameters}

During instantiation, the SVMRankSelector class requires for a SVMRanker object, which must be configured according to which features and resources the user intends to use to rank substitution candidates. The user can then use the ``trainSelector'' function to train the selector given a set of parameters, or the ``trainSelectorWithCrossValidation'' function to train it with cross-validation. Finally, the user can then retrieve a proportion of the candidate substitutions by using the ``selectCandidates'' function. For more information about the parameters of each function, please refer to LEXenstein's documentation.

\subsection{Example}

The code snippet below shows the SVMRankSelector class being used:

\begin{lstlisting}
from lexenstein.morphadorner import MorphAdornerToolkit
from lexenstein.generators import *
from lexenstein.selectors import *
from lexenstein.features import *
from lexenstein.spelling import *
from lexenstein.rankers import *

nc = NorvigCorrector('spelling_model.bin', format='bin')

m = MorphAdornerToolkit('./morph/')

wg = WordnetGenerator(m, nc, './pos_model.tagger', './stanford-postagger.jar', '/usr/bin/java')
subs = wg.getSubstitutions('lexmturk.txt')

fe = FeatureEstimator()
fe.addCollocationalFeature('lm.bin', 0, 0, 'Complexity')
fe.addSenseCountFeature('Simplicity')

sr = SVMRanker(fe, './svm-rank/')
ss = SVMRankSelector(sr)
ss.trainSelectorWithCrossValidation('lexmturk.txt', 'f1.txt', 'm.txt', 5, 0.25, './temp/', 0)
selected = ss.selectCandidates(subs, 'lexmturk.txt', 'f2.txt', 's1.txt', 'temp.txt', 0.25)
\end{lstlisting}










\section{VoidSelector}

Does not perform any type of explicit substitution selection, and selects all possible substitutions generated for a given target word.

\subsection{Parameters}

During instantiation, the VoidSelector class requires no parameters.

\subsection{Example}

The code snippet below shows the VoidSelector class being used:

\begin{lstlisting}
from lexenstein.generators import *
from lexenstein.selectors import *
from lexenstein.spelling import *

nc = NorvigCorrector('spelling_model.bin', format='bin')

m = MorphAdornerToolkit('./morph/')

wg = WordnetGenerator(m, nc, './pos_model.tagger', './stanford-postagger.jar', '/usr/bin/java')
subs = wg.getSubstitutions('lexmturk.txt')

voidselector = VoidSelector()
selected = voidselector.selectCandidates(subs, 'lexmturk.txt')
\end{lstlisting}